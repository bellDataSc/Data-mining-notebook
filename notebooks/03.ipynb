def run_extraction_pipeline(pdf_path, output_path):
    print(f"Starting extraction for: {pdf_path}")
    
    # --- REGEX PATTERNS ---
    # Captures Price at the END of the line (e.g., "R$ 1.200,00")
    regex_price = re.compile(r"(R\$\s?[\d\.]+,[\d]{2})$")
    # Captures Code at the START of the line (7+ alphanumeric chars)
    regex_code = re.compile(r"^([A-Z0-9\.]{7,})")

    # --- STATE VARIABLES ---
    current_family = "START_OF_FILE"
    last_was_title = False
    buffer_data = []
    total_records = 0
    
    # Remove old file if exists
    if os.path.exists(output_path):
        os.remove(output_path)

    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        print(f"Total pages to process: {total_pages}")
        
        for i, page in enumerate(pdf.pages):
            page_num = i + 1
            text = page.extract_text()
            
            if not text: continue
            
            lines = text.split('\n')
            
            for line in lines:
                line = line.strip()
                # Skip Metadata/Headers
                if not line or "Página" in line or "Tabela de Preços" in line or "Moeda:" in line: continue
                if "Código" in line and "Descrição" in line: continue

                # 1. Match Code (Anchor Start)
                match_code = regex_code.search(line)
                if not match_code: continue 
                
                code = match_code.group(1)
                
                # 2. Match Price (Anchor End) -> Determines if it's a PRODUCT or FAMILY
                match_price = regex_price.search(line)
                
                if match_price:
                    # === IT IS A PRODUCT ===
                    price_raw = match_price.group(1)
                    
                    # Extract content between Code and Price
                    middle_content = line[len(code):].replace(price_raw, "").strip()
                    
                    # Parse Description vs Unit
                    description, unit = parse_line_content(middle_content)
                    
                    buffer_data.append({
                        "Page": page_num,
                        "Family": current_family,
                        "Code": code,
                        "Description": description,
                        "Unit": unit,
                        "Price": price_raw 
                    })
                    
                    last_was_title = False # Reset title sequence
                    
                else:
                    # === IT IS A FAMILY HEADER ===
                    family_name = line[len(code):].strip()
                    
                    if len(family_name) > 3:
                        # Hierarchy Logic: Parent | Child detection
                        if last_was_title:
                            current_family = current_family + " | " + family_name
                        else:
                            current_family = family_name
                        
                        last_was_title = True

            # --- BATCH SAVING (CHECKPOINT) ---
            if page_num % BATCH_SIZE == 0 or page_num == total_pages:
                if buffer_data:
                    df_chunk = pd.DataFrame(buffer_data)
                    
                    # Append mode ('a')
                    header_mode = not os.path.exists(output_path)
                    df_chunk.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig', mode='a', header=header_mode)
                    
                    total_records += len(df_chunk)
                    print(f"--> Checkpoint: Page {page_num}/{total_pages} processed. Total records: {total_records}")
                    
                    buffer_data = [] # Clear RAM

    print(f"\n✅ Extraction finished! Total items: {total_records}")

# PDF Extraction Pipeline: Construction Inputs (ETL)

**Author:** Bel Cruz
**Context:** This notebook demonstrates an ETL pipeline designed to extract structured data from unstructured PDF reports.
**Key Features:**
- **Streaming Processing:** Handles large files (~1,700 pages) using batch processing to optimize RAM usage.
- **Regex Parsing:** Extracts data without relying on fixed table grids.
- **Hierarchy Reconstruction:** Rebuilds "Parent | Child" relationships for product families.


import pdfplumber
import pandas as pd
import re
import os


INPUT_PDF = "Embasa - Tabela de Pre√ßos 2025 - INSUMOS JUNHO (1).pdf" 
OUTPUT_CSV = "extracted_dataset.csv"
BATCH_SIZE = 100  




